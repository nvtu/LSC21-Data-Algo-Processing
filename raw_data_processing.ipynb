{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from utils import create_folder, preprocess_dict_keys, get_image_id, get_month, get_year, get_week_day, part_of_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = configparser.ConfigParser()\n",
    "cp.read('config.ini')\n",
    "raw_data_path = cp['DATA_PATH']['raw_data_path']\n",
    "processed_data_path = cp['DATA_PATH']['processed_data_path']\n",
    "images_path = cp['DATA_PATH']['images_path']\n",
    "# Create output folder if it does not exist\n",
    "create_folder(processed_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a white list of validated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get black list image_path\n",
    "lsc2021_removed_list_fp = os.path.join(raw_data_path, 'lsc21-removed-list.txt')\n",
    "lsc2021_removed_list = [get_image_id(line.rstrip()) for line in open(lsc2021_removed_list_fp, 'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of image ids\n",
    "image_list_path = os.path.join(raw_data_path, 'raw_image_paths.txt')\n",
    "white_list_path = os.path.join(processed_data_path, 'white_list_image_ids.txt')\n",
    "white_list_image_path = os.path.join(processed_data_path, 'white_list_image_paths.txt')\n",
    "\n",
    "# Create an image_path list file if it does not exist\n",
    "if not os.path.exists(image_list_path):\n",
    "    image_path_list = []\n",
    "    for date in os.listdir(images_path):\n",
    "        date_path = os.path.join(images_path, date)\n",
    "        image_paths = sorted([os.path.join(date_path, image_name) for image_name in os.listdir(date_path)])\n",
    "        image_path_list += image_paths \n",
    "    with open(image_list_path, 'w') as f:\n",
    "        for image_path in image_path_list:\n",
    "            print(image_path, file = f)\n",
    "\n",
    "if not os.path.exists(white_list_path):\n",
    "    # Load the image_path list\n",
    "    image_path_list = [line.rstrip() for line in open(image_list_path, 'r').readlines()]\n",
    "    image_id_list = [get_image_id(image_path) for image_path in image_path_list]\n",
    "\n",
    "    # Generate a white-list image ids\n",
    "    image_id_white_list = list(filter(lambda image_id: image_id not in lsc2021_removed_list, image_id_list))\n",
    "    with open(white_list_path, 'w') as f:\n",
    "        for image_id in image_id_white_list:\n",
    "            print(image_id, file = f)\n",
    "    \n",
    "    # Generate corresponding white-list image paths\n",
    "    white_list_index = filter(lambda item: item[1] in image_id_white_list, enumerate(image_id_list))\n",
    "    with open(white_list_image_path, 'w') as f:\n",
    "        for item in white_list_index:\n",
    "            index, _ = item\n",
    "            print(image_path_list[index], file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image id white list and image path white list\n",
    "image_id_white_list = [line.rstrip() for line in open(white_list_path, 'r').readlines()]\n",
    "image_path_white_list = [line.rstrip() for line in open(white_list_image_path, 'r').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a combined Scaled YOLOv4 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov4_features_file_path = os.path.join(processed_data_path, 'ScaledYOLOv4_concepts.json')\n",
    "\n",
    "if not os.path.exists(yolov4_features_file_path):\n",
    "    # Confidence threshold set in YOLOv4 detect.py file was 0.7\n",
    "    combined_yolo_features = {}\n",
    "    for image_path in image_path_white_list:\n",
    "        date, image_name = image_path.split('/')[-2:]\n",
    "        image_id = get_image_id(image_name)\n",
    "        concept_path = os.path.join(raw_data_path, 'ScaledYOLOv4_Features', date, image_id + '.txt')\n",
    "        combined_yolo_features[image_id] = []\n",
    "        if os.path.exists(concept_path):\n",
    "            detected_objects = [line.rstrip() for line in open(concept_path, 'r').readlines()]\n",
    "            for obj in detected_objects:\n",
    "                obj_name, *r = obj.split()\n",
    "                combined_yolo_features[image_id].append(obj_name)\n",
    "    with open(yolov4_features_file_path, 'w') as f:\n",
    "        json.dump(combined_yolo_features, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a combined Microsoft Tags Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microsoft_tags_file_path = os.path.join(raw_data_path, 'microsoft_tags.json')\n",
    "combined_microsoft_tags_path = os.path.join(processed_data_path, 'MicrosoftTags_concepts.json')\n",
    "\n",
    "if not os.path.exists(combined_microsoft_tags_path):\n",
    "    MICROSOFT_TAGS_CONFIDENCE_THRESHOLD = 0.7\n",
    "    combined_microsoft_tags = {}    \n",
    "    \n",
    "    # Load raw data\n",
    "    with open(microsoft_tags_file_path, 'r') as f:\n",
    "        microsoft_tags = json.load(f)\n",
    "    \n",
    "    # Pre-process microsoft tags\n",
    "    microsoft_tags = preprocess_dict_keys(microsoft_tags)\n",
    "\n",
    "    for image_path in image_path_white_list:\n",
    "        image_id = get_image_id(image_path)\n",
    "        combined_microsoft_tags[image_id] = []\n",
    "        try:\n",
    "            for concept_name, conf_score in microsoft_tags[image_id].items():\n",
    "                if conf_score >= MICROSOFT_TAGS_CONFIDENCE_THRESHOLD:\n",
    "                    combined_microsoft_tags[image_id].append(concept_name)\n",
    "        except: continue\n",
    "\n",
    "    with open(combined_microsoft_tags_path, 'w') as f:\n",
    "        json.dump(combined_microsoft_tags, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a combined OCR Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_file_path = os.path.join(raw_data_path, 'OCR_LSC.json')\n",
    "combined_ocr_file_path = os.path.join(processed_data_path, 'OCR_concepts.json')\n",
    "\n",
    "if not os.path.exists(combined_ocr_file_path):\n",
    "    combined_ocr = {}\n",
    "    \n",
    "    # Load raw data\n",
    "    with open(ocr_file_path, 'r') as f:\n",
    "        ocr = json.load(f)\n",
    "    \n",
    "    # Pre-process ocr tags\n",
    "    ocr = preprocess_dict_keys(ocr)\n",
    "    \n",
    "    for image_path in image_path_white_list:\n",
    "        image_id = get_image_id(image_path)\n",
    "        combined_ocr[image_id] = ''\n",
    "        try:\n",
    "            combined_ocr[image_id] = ocr[image_id]\n",
    "        except: continue\n",
    "    \n",
    "    with open(combined_ocr_file_path, 'w') as f:\n",
    "        json.dump(combined_ocr, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a combined Visual Genome Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nms import nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_genome_path = os.path.join(raw_data_path, 'visual_genome_res101', 'visual_genome_res101', 'detection')\n",
    "combined_visual_genome_path = os.path.join(processed_data_path, 'VisualGenomeRes101_concepts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(combined_visual_genome_path):\n",
    "    # Combine raw visual genome concepts & bboxes & scores\n",
    "    raw_visual_genome = {}\n",
    "    for image_path in image_path_white_list:\n",
    "        date, image_name = image_path.split('/')[-2:]\n",
    "        image_id = get_image_id(image_name)\n",
    "        concept_path = os.path.join(visual_genome_path, date, image_id + '.json')\n",
    "        raw_visual_genome[image_id] = []\n",
    "        if os.path.exists(concept_path):\n",
    "            detected_concepts = json.load(open(concept_path, 'r'))\n",
    "            for concept in detected_concepts:\n",
    "                visual_concept = f\"{concept['attribute']} {concept['class']}\" if 'attribute' in concept else f\"{concept['class']}\"\n",
    "                bbox = concept['bbox']\n",
    "                score = concept['score']\n",
    "                raw_visual_genome[image_id].append((visual_concept, bbox, score)) \n",
    "        \n",
    "    # Running Non-maximum suppression on the extracted concepts \n",
    "    # of Visual Genome ResNet-101\n",
    "    NMS_THRESH = 0.3\n",
    "    CONF_THRESHOLD = 0.5\n",
    "    refined_visual_genome = {}\n",
    "    combined_visual_genome = {}\n",
    "    cnt_same = 0\n",
    "    for image_id, concepts in tqdm(raw_visual_genome.items()):\n",
    "        refined_visual_genome[image_id] = []\n",
    "        combined_visual_genome[image_id] = []\n",
    "        bboxes = np.array([np.array(item[1]) for item in concepts])\n",
    "        scores = np.array([item[2] for item in concepts])\n",
    "        dets = np.hstack((bboxes, scores[:, np.newaxis])).astype(np.float32)\n",
    "        keeps = nms(dets, NMS_THRESH)\n",
    "        if len(keeps) == len(concepts):\n",
    "            cnt_same += 1\n",
    "        for i in keeps:\n",
    "            refined_visual_genome[image_id].append('{}, {} {} {} {}, {}'.format(concepts[i][0], *concepts[i][1], concepts[i][2]))\n",
    "            score = float(concepts[i][2])\n",
    "            if score >= CONF_THRESHOLD:\n",
    "                combined_visual_genome[image_id].append(concepts[i][0])\n",
    "    \n",
    "    # Save the combined nms-ed visual genome concepts\n",
    "    with open(combined_visual_genome_path, 'w') as f:\n",
    "        json.dump(combined_visual_genome, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize random images with visual genome concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def vis_detections(im, dets, thresh=0.5):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    for d in dets:\n",
    "        class_name, bbox, score = d.split(',')\n",
    "        score = float(score)\n",
    "        bbox = list(map(lambda c: float(c), bbox.split()))\n",
    "        if score >= thresh:\n",
    "            ax.add_patch(\n",
    "                plt.Rectangle((bbox[0], bbox[1]),\n",
    "                            bbox[2] - bbox[0],\n",
    "                            bbox[3] - bbox[1], fill=False,\n",
    "                            edgecolor='red', linewidth=3.5)\n",
    "                )\n",
    "            ax.text(bbox[0], bbox[1] - 2,\n",
    "                    '{:s} {:.3f}'.format(class_name, score),\n",
    "                    bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                    fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('{} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                  thresh),\n",
    "                  fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = random.choice(image_path_white_list)\n",
    "image_id = get_image_id(random_image_path)\n",
    "im = cv2.imread(random_image_path)\n",
    "# annotations = refined_visual_genome[image_id]\n",
    "# vis_detections(im, annotations, thresh = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Combined Place Categories Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsc2020_visual_concept_fp = os.path.join(raw_data_path, 'lsc2020-visual-concepts.csv')\n",
    "combined_place_categories_fp = os.path.join(processed_data_path, 'combined_place_categories.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "vc_metadata = pd.read_csv(lsc2020_visual_concept_fp, low_memory = False)\n",
    "filtered_columns = ['image_path'] + \\\n",
    "    ['category_top{:02d}'.format(i) for i in range(1, 4)] + ['category_top{:02d}_score'.format(i) for i in range(1, 4)]\n",
    "filtered_vc_data = vc_metadata[filtered_columns]\n",
    "filtered_vc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boxplot = filtered_vc_data.boxplot(column=['category_top01_score', 'category_top02_score', 'category_top03_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(combined_place_categories_fp):\n",
    "    PLACECNN_SCORE_THRESH = 0.2\n",
    "    combined_place_category = {}\n",
    "    image_ids = list(map(lambda path: get_image_id(path), filtered_vc_data['image_path'].values))\n",
    "    for image_path in tqdm(image_path_white_list):\n",
    "        date, image_name = image_path.split('/')[-2:]\n",
    "        image_id = get_image_id(image_name)\n",
    "        combined_place_category[image_id] = []\n",
    "        try:\n",
    "            row_index = image_ids.index(image_id)\n",
    "            _, cat1, cat2, cat3, score1, score2, score3 = filtered_vc_data.iloc[row_index].values\n",
    "            if score1 > PLACECNN_SCORE_THRESH:\n",
    "                combined_place_category[image_id].append(' '.join(cat1.split('_')))\n",
    "            if score2 > PLACECNN_SCORE_THRESH:\n",
    "                combined_place_category[image_id].append(' '.join(cat2.split('_')))\n",
    "            if score3 > PLACECNN_SCORE_THRESH:\n",
    "                combined_place_category[image_id].append(' '.join(cat3.split('_')))\n",
    "        except: print(image_path)\n",
    "    \n",
    "    with open(combined_place_categories_fp, 'w') as f:\n",
    "        json.dump(combined_place_category, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Combined Date-time, GPS, and Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "lsc2020_metadata_fp = os.path.join(raw_data_path, 'lsc2020-metadata.csv')\n",
    "time_alignment_fp = os.path.join(raw_data_path, 'LSC_time_alignments.csv')\n",
    "combined_dt_gps_activity_fp = os.path.join(processed_data_path, 'combined_date_time_gps_activity.json')\n",
    "\n",
    "lsc2020_metadata = pd.read_csv(lsc2020_metadata_fp, low_memory = False, keep_default_na = False, na_values = None)\n",
    "time_alignments = pd.read_csv(time_alignment_fp, sep = ',')\n",
    "filtered_metadata = lsc2020_metadata[['minute_id', 'local_time', 'semantic_name', 'lat', 'lon', 'activity_type']]\n",
    "filtered_metadata.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-align UTC time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_aligned_df = filtered_metadata.copy(deep = True)\n",
    "for value in time_alignments.values:\n",
    "    date, _, delta = value\n",
    "    if delta == 0: continue \n",
    "    date = ''.join(date.split('-'))\n",
    "    date_filtered_df = filtered_metadata[filtered_metadata['minute_id'].str.contains(date)]\n",
    "    minute_ids = date_filtered_df['minute_id'].values\n",
    "    local_time = date_filtered_df['local_time'].values\n",
    "    \n",
    "    # Align minute ids\n",
    "    minute_ids = list(map(lambda dt: \n",
    "            (datetime.datetime.strptime(dt, '%Y%m%d_%H%M') + datetime.timedelta(minutes = delta))\n",
    "            .strftime('%Y%m%d_%H%M'), minute_ids))\n",
    "    # Align corresponding local time\n",
    "    local_time = list(map(lambda dt: \n",
    "            (datetime.datetime.strptime(dt, '%Y-%m-%d_%H:%M') + datetime.timedelta(minutes = delta))\n",
    "            .strftime('%Y-%m-%d_%H:%M'), local_time))\n",
    "\n",
    "    # Update to data-frame\n",
    "    indices = date_filtered_df.index\n",
    "    time_aligned_df.loc[indices, 'minute_id'] = minute_ids\n",
    "    time_aligned_df.loc[indices, 'local_time'] = local_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(combined_dt_gps_activity_fp):\n",
    "    combined_dt_gps_activity = {}\n",
    "    for image_path in tqdm(image_path_white_list):\n",
    "        date = image_path.split('/')[-2]\n",
    "        year = get_year(date)\n",
    "        minute_id = ''\n",
    "        image_id = get_image_id(image_path)\n",
    "        try:\n",
    "            if year == 2015 or year == 2018:\n",
    "                d, t = image_id.split('_')[-2:]\n",
    "                minute_id = '_'.join([d, t[:4]])\n",
    "            elif year == 2016:\n",
    "                d, t = image_id.split('_')[:2]\n",
    "                minute_id = '_'.join([d, t[:4]])\n",
    "            row_index = list(time_aligned_df['minute_id'].values).index(minute_id)\n",
    "            _, local_time, location_name, lat, lon, activity_type = time_aligned_df.iloc[row_index].values\n",
    "            _date, _local_time = local_time.split('_')\n",
    "            _local_time = datetime.time(int(_local_time[:2]), int(_local_time[3:]), 0)\n",
    "            wod = get_week_day(_date)\n",
    "            month = get_month(_date)\n",
    "            year = get_year(_date)\n",
    "            pod = part_of_day(_local_time)\n",
    "            combined_dt_gps_activity[image_id] = {\n",
    "                'date': _date,\n",
    "                'local_time': local_time,\n",
    "                'day_of_week': wod,\n",
    "                'month': month,\n",
    "                'year': year,\n",
    "                'part_of_day': pod,\n",
    "                'activity_type': '' if activity_type == 'NULL' else activity_type,\n",
    "                'gps': [float(lat), float(lon)] if lat != 'NULL' and lon != 'NULL' else [],\n",
    "                'location_name': location_name,\n",
    "            }\n",
    "        except Exception as e: \n",
    "            print(image_path)\n",
    "    \n",
    "    with open(combined_dt_gps_activity_fp, 'w') as f:\n",
    "        json.dump(combined_dt_gps_activity, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
