{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from utils import create_folder, preprocess_dict_keys, get_image_id, get_month, get_year, get_week_day, part_of_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = configparser.ConfigParser()\n",
    "cp.read('config.ini')\n",
    "raw_data_path = cp['DATA_PATH']['raw_data_path']\n",
    "processed_data_path = cp['DATA_PATH']['processed_data_path']\n",
    "images_path = cp['DATA_PATH']['images_path']\n",
    "# Create output folder if it does not exist\n",
    "create_folder(processed_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a white list of validated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get black list image_path\n",
    "lsc2021_removed_list_fp = os.path.join(raw_data_path, 'lsc21-removed-list.txt')\n",
    "lsc2021_removed_list = [get_image_id(line.rstrip()) for line in open(lsc2021_removed_list_fp, 'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of image ids\n",
    "image_list_path = os.path.join(raw_data_path, 'raw_image_paths.txt')\n",
    "white_list_path = os.path.join(processed_data_path, 'white_list_image_ids.txt')\n",
    "white_list_image_path = os.path.join(processed_data_path, 'white_list_image_paths.txt')\n",
    "\n",
    "# Create an image_path list file if it does not exist\n",
    "if not os.path.exists(image_list_path):\n",
    "    image_path_list = []\n",
    "    for date in os.listdir(images_path):\n",
    "        date_path = os.path.join(images_path, date)\n",
    "        image_paths = sorted([os.path.join(date_path, image_name) for image_name in os.listdir(date_path)])\n",
    "        image_path_list += image_paths \n",
    "    with open(image_list_path, 'w') as f:\n",
    "        for image_path in image_path_list:\n",
    "            print(image_path, file = f)\n",
    "\n",
    "if not os.path.exists(white_list_path):\n",
    "    # Load the image_path list\n",
    "    image_path_list = [line.rstrip() for line in open(image_list_path, 'r').readlines()]\n",
    "    image_id_list = [get_image_id(image_path) for image_path in image_path_list]\n",
    "\n",
    "    # Generate a white-list image ids\n",
    "    image_id_white_list = list(filter(lambda image_id: image_id not in lsc2021_removed_list, image_id_list))\n",
    "    with open(white_list_path, 'w') as f:\n",
    "        for image_id in image_id_white_list:\n",
    "            print(image_id, file = f)\n",
    "    \n",
    "    # Generate corresponding white-list image paths\n",
    "    white_list_index = filter(lambda item: item[1] in image_id_white_list, enumerate(image_id_list))\n",
    "    with open(white_list_image_path, 'w') as f:\n",
    "        for item in white_list_index:\n",
    "            index, _ = item\n",
    "            print(image_path_list[index], file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image id white list and image path white list\n",
    "image_id_white_list = [line.rstrip() for line in open(white_list_path, 'r').readlines()]\n",
    "image_path_white_list = [line.rstrip() for line in open(white_list_image_path, 'r').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a combined Scaled YOLOv4 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov4_features_file_path = os.path.join(processed_data_path, 'ScaledYOLOv4_concepts.json')\n",
    "\n",
    "if not os.path.exists(yolov4_features_file_path):\n",
    "    # Confidence threshold set in YOLOv4 detect.py file was 0.7\n",
    "    combined_yolo_features = {}\n",
    "    for image_path in image_path_white_list:\n",
    "        date, image_name = image_path.split('/')[-2:]\n",
    "        image_id = get_image_id(image_name)\n",
    "        concept_path = os.path.join(raw_data_path, 'ScaledYOLOv4_Features', date, image_id + '.txt')\n",
    "        combined_yolo_features[image_id] = []\n",
    "        if os.path.exists(concept_path):\n",
    "            detected_objects = [line.rstrip() for line in open(concept_path, 'r').readlines()]\n",
    "            for obj in detected_objects:\n",
    "                obj_name, *r = obj.split()\n",
    "                combined_yolo_features[image_id].append(obj_name)\n",
    "    with open(yolov4_features_file_path, 'w') as f:\n",
    "        json.dump(combined_yolo_features, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a combined Microsoft Tags Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "microsoft_tags_file_path = os.path.join(raw_data_path, 'microsoft_tags.json')\n",
    "combined_microsoft_tags_path = os.path.join(processed_data_path, 'MicrosoftTags_concepts.json')\n",
    "\n",
    "if not os.path.exists(combined_microsoft_tags_path):\n",
    "    MICROSOFT_TAGS_CONFIDENCE_THRESHOLD = 0.7\n",
    "    combined_microsoft_tags = {}    \n",
    "    \n",
    "    # Load raw data\n",
    "    with open(microsoft_tags_file_path, 'r') as f:\n",
    "        microsoft_tags = json.load(f)\n",
    "    \n",
    "    # Pre-process microsoft tags\n",
    "    microsoft_tags = preprocess_dict_keys(microsoft_tags)\n",
    "\n",
    "    for image_path in image_path_white_list:\n",
    "        image_id = get_image_id(image_path)\n",
    "        combined_microsoft_tags[image_id] = []\n",
    "        try:\n",
    "            for concept_name, conf_score in microsoft_tags[image_id].items():\n",
    "                if conf_score >= MICROSOFT_TAGS_CONFIDENCE_THRESHOLD:\n",
    "                    combined_microsoft_tags[image_id].append(concept_name)\n",
    "        except: continue\n",
    "\n",
    "    with open(combined_microsoft_tags_path, 'w') as f:\n",
    "        json.dump(combined_microsoft_tags, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a combined OCR Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_file_path = os.path.join(raw_data_path, 'OCR_LSC.json')\n",
    "combined_ocr_file_path = os.path.join(processed_data_path, 'OCR_concepts.json')\n",
    "\n",
    "if not os.path.exists(combined_ocr_file_path):\n",
    "    combined_ocr = {}\n",
    "    \n",
    "    # Load raw data\n",
    "    with open(ocr_file_path, 'r') as f:\n",
    "        ocr = json.load(f)\n",
    "    \n",
    "    # Pre-process ocr tags\n",
    "    ocr = preprocess_dict_keys(ocr)\n",
    "    \n",
    "    for image_path in image_path_white_list:\n",
    "        image_id = get_image_id(image_path)\n",
    "        combined_ocr[image_id] = ''\n",
    "        try:\n",
    "            combined_ocr[image_id] = ocr[image_id]\n",
    "        except: continue\n",
    "    \n",
    "    with open(combined_ocr_file_path, 'w') as f:\n",
    "        json.dump(combined_ocr, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a combined Visual Genome Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nms import nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_genome_path = os.path.join(raw_data_path, 'visual_genome_res101', 'visual_genome_res101', 'detection')\n",
    "combined_visual_genome_path = os.path.join(processed_data_path, 'VisualGenomeRes101_concepts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183272/183272 [00:51<00:00, 3580.55it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(combined_visual_genome_path):\n",
    "    # Combine raw visual genome concepts & bboxes & scores\n",
    "    raw_visual_genome = {}\n",
    "    for image_path in image_path_white_list:\n",
    "        date, image_name = image_path.split('/')[-2:]\n",
    "        image_id = get_image_id(image_name)\n",
    "        concept_path = os.path.join(visual_genome_path, date, image_id + '.json')\n",
    "        raw_visual_genome[image_id] = []\n",
    "        if os.path.exists(concept_path):\n",
    "            detected_concepts = json.load(open(concept_path, 'r'))\n",
    "            for concept in detected_concepts:\n",
    "                visual_concept = f\"{concept['attribute']} {concept['class']}\" if 'attribute' in concept else f\"{concept['class']}\"\n",
    "                bbox = concept['bbox']\n",
    "                score = concept['score']\n",
    "                raw_visual_genome[image_id].append((visual_concept, bbox, score)) \n",
    "        \n",
    "\n",
    "    # Running Non-maximum suppression on the extracted concepts \n",
    "    # of Visual Genome ResNet-101\n",
    "    NMS_THRESH = 0.3\n",
    "    CONF_THRESHOLD = 0.5\n",
    "    refined_visual_genome = {}\n",
    "    combined_visual_genome = {}\n",
    "    cnt_same = 0\n",
    "    for image_id, concepts in tqdm(raw_visual_genome.items()):\n",
    "        refined_visual_genome[image_id] = []\n",
    "        combined_visual_genome[image_id] = []\n",
    "        bboxes = np.array([np.array(item[1]) for item in concepts])\n",
    "        scores = np.array([item[2] for item in concepts])\n",
    "        dets = np.hstack((bboxes, scores[:, np.newaxis])).astype(np.float32)\n",
    "        keeps = nms(dets, NMS_THRESH)\n",
    "        for i in keeps:\n",
    "            refined_visual_genome[image_id].append('{}, {} {} {} {}, {}'.format(concepts[i][0], *concepts[i][1], concepts[i][2]))\n",
    "            score = float(concepts[i][2])\n",
    "            if score >= CONF_THRESHOLD:\n",
    "                combined_visual_genome[image_id].append(concepts[i][0])\n",
    "    \n",
    "    # Save the combined nms-ed visual genome concepts\n",
    "    with open(combined_visual_genome_path, 'w') as f:\n",
    "        json.dump(combined_visual_genome, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize random images with visual genome concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def vis_detections(im, dets, thresh=0.5):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    for d in dets:\n",
    "        class_name, bbox, score = d.split(',')\n",
    "        score = float(score)\n",
    "        bbox = list(map(lambda c: float(c), bbox.split()))\n",
    "        if score >= thresh:\n",
    "            ax.add_patch(\n",
    "                plt.Rectangle((bbox[0], bbox[1]),\n",
    "                            bbox[2] - bbox[0],\n",
    "                            bbox[3] - bbox[1], fill=False,\n",
    "                            edgecolor='red', linewidth=3.5)\n",
    "                )\n",
    "            ax.text(bbox[0], bbox[1] - 2,\n",
    "                    '{:s} {:.3f}'.format(class_name, score),\n",
    "                    bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                    fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('{} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                  thresh),\n",
    "                  fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = random.choice(image_path_white_list)\n",
    "image_id = get_image_id(random_image_path)\n",
    "im = cv2.imread(random_image_path)\n",
    "# annotations = refined_visual_genome[image_id]\n",
    "# vis_detections(im, annotations, thresh = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Combined Place Categories Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsc2020_visual_concept_fp = os.path.join(raw_data_path, 'lsc2020-visual-concepts.csv')\n",
    "combined_place_categories_fp = os.path.join(processed_data_path, 'combined_place_categories.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>category_top01</th>\n",
       "      <th>category_top02</th>\n",
       "      <th>category_top03</th>\n",
       "      <th>category_top01_score</th>\n",
       "      <th>category_top02_score</th>\n",
       "      <th>category_top03_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATASETS/LSC2020/2015-02-23/b00000000_21i6bq_2...</td>\n",
       "      <td>dorm_room</td>\n",
       "      <td>jail_cell</td>\n",
       "      <td>alcove</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATASETS/LSC2020/2015-02-23/b00000001_21i6bq_2...</td>\n",
       "      <td>wet_bar</td>\n",
       "      <td>alcove</td>\n",
       "      <td>church/indoor</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATASETS/LSC2020/2015-02-23/b00000002_21i6bq_2...</td>\n",
       "      <td>television_room</td>\n",
       "      <td>airplane_cabin</td>\n",
       "      <td>server_room</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATASETS/LSC2020/2015-02-23/b00000003_21i6bq_2...</td>\n",
       "      <td>television_studio</td>\n",
       "      <td>server_room</td>\n",
       "      <td>chemistry_lab</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATASETS/LSC2020/2015-02-23/b00000004_21i6bq_2...</td>\n",
       "      <td>server_room</td>\n",
       "      <td>chemistry_lab</td>\n",
       "      <td>airplane_cabin</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path     category_top01  \\\n",
       "0  DATASETS/LSC2020/2015-02-23/b00000000_21i6bq_2...          dorm_room   \n",
       "1  DATASETS/LSC2020/2015-02-23/b00000001_21i6bq_2...            wet_bar   \n",
       "2  DATASETS/LSC2020/2015-02-23/b00000002_21i6bq_2...    television_room   \n",
       "3  DATASETS/LSC2020/2015-02-23/b00000003_21i6bq_2...  television_studio   \n",
       "4  DATASETS/LSC2020/2015-02-23/b00000004_21i6bq_2...        server_room   \n",
       "\n",
       "   category_top02  category_top03  category_top01_score  category_top02_score  \\\n",
       "0       jail_cell          alcove                 0.144                 0.112   \n",
       "1          alcove   church/indoor                 0.057                 0.046   \n",
       "2  airplane_cabin     server_room                 0.141                 0.119   \n",
       "3     server_room   chemistry_lab                 0.165                 0.095   \n",
       "4   chemistry_lab  airplane_cabin                 0.149                 0.082   \n",
       "\n",
       "   category_top03_score  \n",
       "0                 0.092  \n",
       "1                 0.045  \n",
       "2                 0.078  \n",
       "3                 0.075  \n",
       "4                 0.073  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "vc_metadata = pd.read_csv(lsc2020_visual_concept_fp, low_memory = False)\n",
    "filtered_columns = ['image_path'] + \\\n",
    "    ['category_top{:02d}'.format(i) for i in range(1, 4)] + ['category_top{:02d}_score'.format(i) for i in range(1, 4)]\n",
    "filtered_vc_data = vc_metadata[filtered_columns]\n",
    "filtered_vc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot = filtered_vc_data.boxplot(column=['category_top01_score', 'category_top02_score', 'category_top03_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(combined_place_categories_fp):\n",
    "    PLACECNN_SCORE_THRESH = 0.2\n",
    "    combined_place_category = {}\n",
    "    image_ids = list(map(lambda path: get_image_id(path), filtered_vc_data['image_path'].values))\n",
    "    for image_path in tqdm(image_path_white_list):\n",
    "        date, image_name = image_path.split('/')[-2:]\n",
    "        image_id = get_image_id(image_name)\n",
    "        combined_place_category[image_id] = []\n",
    "        try:\n",
    "            row_index = image_ids.index(image_id)\n",
    "            _, cat1, cat2, cat3, score1, score2, score3 = filtered_vc_data.iloc[row_index].values\n",
    "            if score1 > PLACECNN_SCORE_THRESH:\n",
    "                combined_place_category[image_id].append(' '.join(cat1.split('_')))\n",
    "            if score2 > PLACECNN_SCORE_THRESH:\n",
    "                combined_place_category[image_id].append(' '.join(cat2.split('_')))\n",
    "            if score3 > PLACECNN_SCORE_THRESH:\n",
    "                combined_place_category[image_id].append(' '.join(cat3.split('_')))\n",
    "        except: print(image_path)\n",
    "    \n",
    "    with open(combined_place_categories_fp, 'w') as f:\n",
    "        json.dump(combined_place_category, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Combined Date-time, GPS, and Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minute_id</th>\n",
       "      <th>local_time</th>\n",
       "      <th>semantic_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>activity_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164155</th>\n",
       "      <td>20180531_2355</td>\n",
       "      <td>2018-06-01_00:55</td>\n",
       "      <td>Home</td>\n",
       "      <td>53.389933</td>\n",
       "      <td>-6.1457153</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164156</th>\n",
       "      <td>20180531_2356</td>\n",
       "      <td>2018-06-01_00:56</td>\n",
       "      <td>Home</td>\n",
       "      <td>53.389933</td>\n",
       "      <td>-6.1457153</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164157</th>\n",
       "      <td>20180531_2357</td>\n",
       "      <td>2018-06-01_00:57</td>\n",
       "      <td>Home</td>\n",
       "      <td>53.389933</td>\n",
       "      <td>-6.1457153</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164158</th>\n",
       "      <td>20180531_2358</td>\n",
       "      <td>2018-06-01_00:58</td>\n",
       "      <td>Home</td>\n",
       "      <td>53.389933</td>\n",
       "      <td>-6.1457153</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164159</th>\n",
       "      <td>20180531_2359</td>\n",
       "      <td>2018-06-01_00:59</td>\n",
       "      <td>Home</td>\n",
       "      <td>53.389933</td>\n",
       "      <td>-6.1457153</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            minute_id        local_time semantic_name        lat         lon  \\\n",
       "164155  20180531_2355  2018-06-01_00:55          Home  53.389933  -6.1457153   \n",
       "164156  20180531_2356  2018-06-01_00:56          Home  53.389933  -6.1457153   \n",
       "164157  20180531_2357  2018-06-01_00:57          Home  53.389933  -6.1457153   \n",
       "164158  20180531_2358  2018-06-01_00:58          Home  53.389933  -6.1457153   \n",
       "164159  20180531_2359  2018-06-01_00:59          Home  53.389933  -6.1457153   \n",
       "\n",
       "       activity_type  \n",
       "164155          NULL  \n",
       "164156          NULL  \n",
       "164157          NULL  \n",
       "164158          NULL  \n",
       "164159          NULL  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata\n",
    "lsc2020_metadata_fp = os.path.join(raw_data_path, 'lsc2020-metadata.csv')\n",
    "time_alignment_fp = os.path.join(raw_data_path, 'LSC_time_alignments.csv')\n",
    "combined_dt_gps_activity_fp = os.path.join(processed_data_path, 'combined_date_time_gps_activity.json')\n",
    "\n",
    "lsc2020_metadata = pd.read_csv(lsc2020_metadata_fp, low_memory = False, keep_default_na = False, na_values = None)\n",
    "time_alignments = pd.read_csv(time_alignment_fp, sep = ',')\n",
    "filtered_metadata = lsc2020_metadata[['minute_id', 'local_time', 'semantic_name', 'lat', 'lon', 'activity_type']]\n",
    "filtered_metadata.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-align UTC time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_aligned_df = filtered_metadata.copy(deep = True)\n",
    "for value in time_alignments.values:\n",
    "    date, _, delta = value\n",
    "    if delta == 0: continue \n",
    "    date = ''.join(date.split('-'))\n",
    "    date_filtered_df = filtered_metadata[filtered_metadata['minute_id'].str.contains(date)]\n",
    "    minute_ids = date_filtered_df['minute_id'].values\n",
    "    local_time = date_filtered_df['local_time'].values\n",
    "    \n",
    "    # Align minute ids\n",
    "    minute_ids = list(map(lambda dt: \n",
    "            (datetime.datetime.strptime(dt, '%Y%m%d_%H%M') + datetime.timedelta(minutes = delta))\n",
    "            .strftime('%Y%m%d_%H%M'), minute_ids))\n",
    "    # Align corresponding local time\n",
    "    local_time = list(map(lambda dt: \n",
    "            (datetime.datetime.strptime(dt, '%Y-%m-%d_%H:%M') + datetime.timedelta(minutes = delta))\n",
    "            .strftime('%Y-%m-%d_%H:%M'), local_time))\n",
    "\n",
    "    # Update to data-frame\n",
    "    indices = date_filtered_df.index\n",
    "    time_aligned_df.loc[indices, 'minute_id'] = minute_ids\n",
    "    time_aligned_df.loc[indices, 'local_time'] = local_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(combined_dt_gps_activity_fp):\n",
    "    combined_dt_gps_activity = {}\n",
    "    for image_path in tqdm(image_path_white_list):\n",
    "        date = image_path.split('/')[-2]\n",
    "        year = get_year(date)\n",
    "        minute_id = ''\n",
    "        image_id = get_image_id(image_path)\n",
    "        try:\n",
    "            if year == 2015 or year == 2018:\n",
    "                d, t = image_id.split('_')[-2:]\n",
    "                minute_id = '_'.join([d, t[:4]])\n",
    "            elif year == 2016:\n",
    "                d, t = image_id.split('_')[:2]\n",
    "                minute_id = '_'.join([d, t[:4]])\n",
    "            row_index = list(time_aligned_df['minute_id'].values).index(minute_id)\n",
    "            _minute_id, local_time, location_name, lat, lon, activity_type = time_aligned_df.iloc[row_index].values\n",
    "            _date, _local_time = local_time.split('_')\n",
    "            _local_time = datetime.time(int(_local_time[:2]), int(_local_time[3:]), 0)\n",
    "            wod = get_week_day(_date)\n",
    "            month = get_month(_date)\n",
    "            year = get_year(_date)\n",
    "            pod = part_of_day(_local_time)\n",
    "            combined_dt_gps_activity[image_id] = {\n",
    "                'minute_id': _minute_id,\n",
    "                'date': _date,\n",
    "                'local_time': local_time,\n",
    "                'day_of_week': wod,\n",
    "                'month': month,\n",
    "                'year': year,\n",
    "                'part_of_day': pod,\n",
    "                'activity_type': '' if activity_type == 'NULL' else activity_type,\n",
    "                'gps': [float(lat), float(lon)] if lat != 'NULL' and lon != 'NULL' else [],\n",
    "                'location_name': location_name,\n",
    "            }\n",
    "        except Exception as e: \n",
    "            print(image_path)\n",
    "    \n",
    "    with open(combined_dt_gps_activity_fp, 'w') as f:\n",
    "        json.dump(combined_dt_gps_activity, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
